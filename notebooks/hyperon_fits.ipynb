{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/grantdb/lqcd/hyperon-xpt-master\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Get the current working directory\n",
    "cwd = Path(os.getcwd())\n",
    "\n",
    "# Assuming your notebook is in the project root, set the project root as cwd\n",
    "project_root = cwd.parent\n",
    "print(project_root)\n",
    "\n",
    "# If your notebook is in a subdirectory of the project root, you can modify the path accordingly:\n",
    "# project_root = cwd.parent  # Go up one directory level\n",
    "# project_root = cwd.parent.parent  # Go up two directory levels\n",
    "\n",
    "# Add the project root directory to sys.path\n",
    "sys.path.insert(0, str(project_root))\n",
    "# sys.path.append('../')\n",
    "\n",
    "import xpt.fit_analysis as xfa\n",
    "import warnings\n",
    "import corr_fitter.bs_utils as bs\n",
    "import corr_fitter.bs_analysis as bs_analysis\n",
    "import corr_fitter.load_data_priors as ld\n",
    "import corr_fitter.corr_fit_analysis as fa\n",
    "import xpt.priors as priors\n",
    "import xpt.i_o as i_o\n",
    "import xpt.fit_routine as fit\n",
    "import xpt.plots as plots\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib\n",
    "import tqdm\n",
    "import h5py as h5\n",
    "import yaml\n",
    "import io\n",
    "import lsqfit\n",
    "import os\n",
    "import importlib\n",
    "import numpy as np\n",
    "import gvar as gv\n",
    "import pandas as pd\n",
    "# from h5glance import H5Glance\n",
    "import platform\n",
    "\n",
    "warnings.simplefilter(action=\"default\")\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths and other variables\n",
    "if platform.system() == 'Darwin':\n",
    "    file = '/Users/grantdb/lqcd/data/c51_2pt_octet_decuplet.h5'\n",
    "else:\n",
    "    file = '/home/gmoney/lqcd/data/c51_2pt_octet_decuplet.h5'\n",
    "\n",
    "base_dir = \"/home/gmoney/lqcd/hyperon-xpt-master\"\n",
    "input_dir = os.path.join(base_dir, \"tests/input_files\")\n",
    "data_dir = os.path.join(base_dir, \"data\")\n",
    "fit_results_dir = os.path.join(base_dir, \"fit_results\")\n",
    "data_file = '/home/gmoney/lqcd/data/c51_2pt_octet_decuplet.h5'\n",
    "hyperon_data_file = os.path.join(data_dir,\"hyperon_data.h5\")\n",
    "bs_data_file = os.path.join(data_dir, \"hyperon_bs_data.h5\")\n",
    "model_type = \"all\"\n",
    "t_plot_min = 0\n",
    "t_plot_max = 40\n",
    "bs_N = 100\n",
    "bs_seed = \"seed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importlib.reload(i_o)\n",
    "# input_output = i_o.InputOutput()\n",
    "# data = input_output.get_data()\n",
    "# print(data)\n",
    "# scale_setting_data = input_output.get_scale_setting_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pprint\n",
    "# import os.path\n",
    "# fit_results = {}\n",
    "# directory = fit_results_dir\n",
    "\n",
    "# with h5.File('/home/gmoney/lqcd/data/c51_2pt_octet_decuplet.h5', \"r\") as f:\n",
    "#     ens = sorted(list(f.keys()))\n",
    "#     ens.remove('a06m310')\n",
    "#     ens.remove('a09m220')\n",
    "#     ens.remove('a09m220_new_old')\n",
    "#     ens.remove('a09m310_new_old')\n",
    "#     ens.remove('a12m130')\n",
    "\n",
    "#     print(ens)\n",
    "#     for key in ens:\n",
    "#         file_path = os.path.join(directory, key, 'all', 'hyperons')\n",
    "#         if os.path.isfile(file_path):\n",
    "#             loaded_data = gv.load(file_path)\n",
    "#             filtered_data = {}\n",
    "#             for subkey, subvalue in loaded_data.items():\n",
    "#                 if not isinstance(subvalue, dict):\n",
    "#                     filtered_data[subkey] = subvalue\n",
    "#                 else:\n",
    "#                     filtered_e0_values = {k: v for k, v in subvalue.items() if '_E0' in k}\n",
    "#                     if filtered_e0_values:\n",
    "#                         filtered_data[subkey] = filtered_e0_values\n",
    "#             fit_results[key] = filtered_data\n",
    "#         else:\n",
    "#             print(f\"Skipping ensemble {key} because hyperons pickle file is missing.\")\n",
    "#             fit_results[key] = None\n",
    "#     hyperons = {}\n",
    "#     for abbr in ens:\n",
    "#         if fit_results[abbr] is not None:\n",
    "#             hyperons[abbr] = {}\n",
    "#             for hyperon in ['sigma_E0', 'lam_E0', 'xi_E0', 'xi_st_E0', 'sigma_st_E0']:\n",
    "#                 hyperons[abbr][hyperon] = fit_results[abbr]['p'][hyperon]\n",
    "#         else:\n",
    "#             print(f\"Skipping {abbr} because fit_results[{abbr}] is None.\")\n",
    "#     pprint.pprint(hyperons)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'a15m400'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m abbr \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma15m400\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m fit_params \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(input_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mabbr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.py\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m hyperon_fit \u001b[38;5;241m=\u001b[39m \u001b[43mfa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manalyze_hyperon_corrs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mbs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbs_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbs_data_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mbs_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mabbr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbs_N\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbs_N\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbs_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbs_seed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m my_fit \u001b[38;5;241m=\u001b[39m hyperon_fit\u001b[38;5;241m.\u001b[39mget_fit()\n\u001b[1;32m     10\u001b[0m plot2 \u001b[38;5;241m=\u001b[39m hyperon_fit\u001b[38;5;241m.\u001b[39mplot_effective_mass(t_plot_min\u001b[38;5;241m=\u001b[39mt_plot_min, t_plot_max\u001b[38;5;241m=\u001b[39mt_plot_max, model_type\u001b[38;5;241m=\u001b[39mmodel_type,\n\u001b[1;32m     11\u001b[0m                                            show_plot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, show_fit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/lqcd/hyperon-xpt-master/corr_fitter/corr_fit_analysis.py:25\u001b[0m, in \u001b[0;36manalyze_hyperon_corrs\u001b[0;34m(file_path, fit_params_path, model_type, bs, bs_file, bs_path, bs_N, bs_seed)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39manalyze_hyperon_corrs\u001b[39m(file_path, fit_params_path,model_type:\u001b[39mstr\u001b[39m,bs:\u001b[39mbool\u001b[39m\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, bs_file:\u001b[39mstr\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, bs_path:\u001b[39mstr\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, bs_N:\u001b[39mint\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, bs_seed:\u001b[39mstr\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     24\u001b[0m     sys\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mappend(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mdirname(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mabspath(fit_params_path)))\n\u001b[0;32m---> 25\u001b[0m     fp \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39;49mimport_module(fit_params_path\u001b[39m.\u001b[39;49msplit(\u001b[39m'\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m'\u001b[39;49m)[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49msplit(\u001b[39m'\u001b[39;49m\u001b[39m.py\u001b[39;49m\u001b[39m'\u001b[39;49m)[\u001b[39m0\u001b[39;49m])\n\u001b[1;32m     26\u001b[0m     p_dict \u001b[39m=\u001b[39m fp\u001b[39m.\u001b[39mp_dict\n\u001b[1;32m     27\u001b[0m     prior \u001b[39m=\u001b[39m fp\u001b[39m.\u001b[39mprior\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.10/3.10.10/Frameworks/Python.framework/Versions/3.10/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1004\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'a15m400'"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "abbr = 'a15m400'\n",
    "fit_params = os.path.join(input_dir, f\"{abbr}.py\")\n",
    "hyperon_fit = fa.analyze_hyperon_corrs(data_file, fit_params, model_type=model_type,\n",
    "                                               bs=False, bs_file=bs_data_file,\n",
    "                                               bs_path=abbr, bs_N=bs_N, bs_seed=bs_seed)\n",
    "   \n",
    "\n",
    "my_fit = hyperon_fit.get_fit()\n",
    "plot2 = hyperon_fit.plot_effective_mass(t_plot_min=t_plot_min, t_plot_max=t_plot_max, model_type=model_type,\n",
    "                                           show_plot=True, show_fit=True)\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "def generate_latex_line(hyperon_fit):\n",
    "    ordered_keys = ['proton_E0', 'xi_E0', 'sigma_E0', 'lam_E0', 'xi_st_E0', 'delta_E0', 'sigma_st_E0']\n",
    "    latex_line = \"\"\n",
    "\n",
    "    for key in ordered_keys:\n",
    "        if key in hyperon_fit.p:\n",
    "            p = hyperon_fit.p[key]\n",
    "            latex_line += f\"{p} & \"\n",
    "        else:\n",
    "            latex_line += \"& \"\n",
    "\n",
    "    # Remove the last ampersand and space\n",
    "    latex_line = latex_line[:-2]\n",
    "\n",
    "    return latex_line\n",
    "\n",
    "\n",
    "generate_latex_line(hyperon_fit=my_fit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "abbreviations = [f[:-3] for f in os.listdir(input_dir) if f.endswith('.py')]\n",
    "\n",
    "for abbr in abbreviations:\n",
    "    fit_params = os.path.join(input_dir, f\"{abbr}.py\")\n",
    "    if not os.path.exists(fit_params):\n",
    "        print(f\"Error: input file {fit_params} does not exist!\")\n",
    "        continue\n",
    "\n",
    "    with open(fit_params, 'r') as f:\n",
    "        input_file_contents = f.read()\n",
    "\n",
    "    if 'p_dict' not in input_file_contents:\n",
    "        print(f\"Error: input file {fit_params} does not contain a dictionary called 'p_dict'!\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        p_dict = {}\n",
    "        exec(input_file_contents, p_dict)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: Failed to execute the contents of input file {fit_params}!\\n{str(e)}\")\n",
    "        continue\n",
    "\n",
    "    if 'tag' not in p_dict:\n",
    "        print(f\"Warning: input file {fit_params} does not contain a dictionary called 'tag' within the 'p_dict' dictionary! Adding default values...\")\n",
    "        p_dict['tag'] = {\n",
    "            'sigma' : 'sigma',\n",
    "            'sigma_st' : 'sigma_st',\n",
    "            'xi' :  'xi',\n",
    "            'xi_st' : 'xi_st',\n",
    "            'lam' : 'lam',\n",
    "        }\n",
    "\n",
    "    try:\n",
    "        hyperon_fit = fa.analyze_hyperon_corrs(data_file, fit_params, model_type=model_type,\n",
    "                                               bs=False, bs_file=bs_data_file,\n",
    "                                               bs_path=abbr, bs_N=bs_N, bs_seed=bs_seed)\n",
    "    except KeyError:\n",
    "        print(f\"KeyError: Error analyzing hyperons for input file {fit_params}. Skipping abbreviation {abbr}.\")\n",
    "        continue\n",
    "\n",
    "    my_fit = hyperon_fit.get_fit()\n",
    "\n",
    "    out_path = os.path.join(fit_results_dir, abbr, model_type)\n",
    "    ld.pickle_out(fit_out=my_fit, out_path=out_path, species=\"hyperons\")\n",
    "    plot1 = hyperon_fit.return_best_fit_info()\n",
    "    plot2 = hyperon_fit.plot_effective_mass(t_plot_min=t_plot_min, t_plot_max=t_plot_max, model_type=model_type,\n",
    "                                            show_plot=True, show_fit=True)\n",
    "\n",
    "    output_dir = os.path.join(fit_results_dir, abbr, f\"{model_type}_{abbr}\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_pdf = os.path.join(output_dir, 'output.pdf')\n",
    "    with PdfPages(output_pdf) as pp:\n",
    "        pp.savefig(plot1)\n",
    "        pp.savefig(plot2)\n",
    "\n",
    "    params_df = pd.DataFrame(my_fit.p).transpose()\n",
    "\n",
    "    print(\"Abbreviation:\", abbr)\n",
    "    print(tabulate(params_df, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "    # Ask the user if the fit result is acceptable\n",
    "    while True:\n",
    "        result = input(f\"Is the fit result for abbreviation {abbr} acceptable? (y/n): \")\n",
    "        if result == \"y\":\n",
    "            # Save the result and skip this fit in future runs\n",
    "            out_path = 'fit_results/{0}/{1}/'.format(abbr, model_type)\n",
    "            ld.pickle_out(fit_out=my_fit, out_path=out_path, species=\"hyperons\")\n",
    "            break\n",
    "        elif result == \"n\":\n",
    "            break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
